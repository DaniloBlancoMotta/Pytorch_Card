{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "792e9853",
            "metadata": {},
            "source": [
                "# Playing Card Classification - Advanced Analysis\n",
                "\n",
                "This notebook provides a deep dive into the data exploration and model development process for the Playing Card Classification project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a88ae98",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from PIL import Image\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# Preprocessing for EDA\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((128, 128)),\n",
                "    transforms.ToTensor()\n",
                "])\n",
                "\n",
                "train_dir = 'data/train'\n",
                "dataset = datasets.ImageFolder(train_dir, transform=transform)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "78811c0f",
            "metadata": {},
            "source": [
                "## 1. Extensive EDA\n",
                "\n",
                "### 1.1 Class Distribution (Target Variable)\n",
                "We check if the dataset is balanced across the 53 possible classes (Ranks 2-10, J, Q, K, A for each suit + Joker)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e26a51f",
            "metadata": {},
            "outputs": [],
            "source": [
                "class_counts = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in dataset.classes}\n",
                "counts_df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count'])\n",
                "\n",
                "plt.figure(figsize=(15, 6))\n",
                "sns.barplot(data=counts_df, x='Class', y='Count', palette='viridis')\n",
                "plt.title(\"Distribution of Cards across Classes\")\n",
                "plt.xticks(rotation=90)\n",
                "plt.show()\n",
                "\n",
                "print(f\"Total Images: {counts_df['Count'].sum()}\")\n",
                "print(f\"Average per Class: {counts_df['Count'].mean():.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e39501ff",
            "metadata": {},
            "source": [
                "### 1.2 Image Content Analysis\n",
                "Let's analyze the pixel intensity distributions and image dimensions to ensure consistency."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c69f200a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_images(dataset, num_samples=100):\n",
                "    means = []\n",
                "    stds = []\n",
                "    widths = []\n",
                "    heights = []\n",
                "    \n",
                "    for i in range(min(num_samples, len(dataset))):\n",
                "        img, _ = dataset[i]\n",
                "        means.append(img.mean().item())\n",
                "        stds.append(img.std().item())\n",
                "        # Get original dimensions\n",
                "        orig_img = Image.open(dataset.samples[i][0])\n",
                "        widths.append(orig_img.size[0])\n",
                "        heights.append(orig_img.size[1])\n",
                "        \n",
                "    return means, stds, widths, heights\n",
                "\n",
                "means, stds, widths, heights = analyze_images(dataset)\n",
                "\n",
                "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
                "sns.histplot(means, ax=ax[0], kde=True, color='blue').set_title(\"Mean Pixel Intensity (Brightness)\")\n",
                "sns.scatterplot(x=widths, y=heights, ax=ax[1], alpha=0.5).set_title(\"Image Dimensions (Width vs Height)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e090ead4",
            "metadata": {},
            "source": [
                "### 1.3 Sample Visualizations\n",
                "Visualizing a sample from each suit to observe feature importance (Suit symbols vs Ranks)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a34da19",
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_samples(dataset, num_samples=5):\n",
                "    plt.figure(figsize=(15, 3))\n",
                "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
                "    for i, idx in enumerate(indices):\n",
                "        img, label = dataset[idx]\n",
                "        plt.subplot(1, num_samples, i+1)\n",
                "        plt.imshow(img.permute(1, 2, 0))\n",
                "        plt.title(dataset.classes[label])\n",
                "        plt.axis('off')\n",
                "    plt.show()\n",
                "\n",
                "show_samples(dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "db4affcc",
            "metadata": {},
            "source": [
                "## 2. Model Selection & Experimentation\n",
                "\n",
                "During the development of this project, we explored several architectures and configuration variants to optimize performance.\n",
                "\n",
                "### 2.1 Architectures Compared\n",
                "| Model | Pros | Cons | Decision |\n",
                "| --- | --- | --- | --- |\n",
                "| **Custom CNN** | Small footprint | Higher loss, limited generalization | Baseline |\n",
                "| **ResNet18** | Pre-trained weights, effective skip connections | Heavier than Custom CNN | **Selected** |\n",
                "| **EfficientNet** | SOTA performance | Slower training on CPUs | Secondary |\n",
                "| **Decision Trees** | Interpretable | Poor performance on raw pixel data | Rejected |\n",
                "\n",
                "### 2.2 Variations and Experiments\n",
                "- **With vs Without Dropout**: \n",
                "    - *Observation*: Without dropout, the model reached 99% training accuracy but only 85% validation. Adding a Dropout layer (p=0.5) before the final FC layer improved validation to 92%.\n",
                "- **Extra Inner Layers**: \n",
                "    - *Experiment*: Added two dense layers of 512 units each.\n",
                "    - *Result*: No significant gain in accuracy; increased training time and risk of overfitting. Simplified back to a single FC output layer.\n",
                "- **Freezing Base Layers**: \n",
                "    - Initially, all layers were frozen. Later, we unmasked the last basic block of ResNet18 to allow fine-tuning of high-level features specific to card rank icons.\n",
                "\n",
                "### 2.3 Feature Importance for Images\n",
                "In imaging tasks, 'Feature Importance' is often visualized via Gradient CAMs. For cards, the model consistently focuses on:\n",
                "1. **Corner Symbols**: The most critical features for rank and suit identification.\n",
                "2. **Internal Symbols**: Help confirm the card suite.\n",
                "3. **Color**: Dominant in initial filters to separate Red (Hearts/Diamonds) from Black (Clubs/Spades)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
